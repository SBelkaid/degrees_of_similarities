{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract patterns from Distributional Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3297 2860 437\n"
     ]
    }
   ],
   "source": [
    "from base import extract_wp\n",
    "import numpy as np\n",
    "#extract word pairs from training and testing dataset\n",
    "word_pairs_dir_test = 'SemEval-2012-Complete-Data-Package/Testing/Phase1Answers/'\n",
    "wp_test = extract_wp(word_pairs_dir_test)\n",
    "word_pairs_dir_train = 'SemEval-2012-Complete-Data-Package/Training/Phase1Answers/'\n",
    "wp_train = extract_wp(word_pairs_dir_train)\n",
    "wp = wp_test + wp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2017-02-03 10:14:08.652871\n",
      "End: 2017-02-03 17:50:02.032837\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print 'Start: '+ str(datetime.now())\n",
    "#extract links from DM\n",
    "dm = open('typedm.txt', 'r')\n",
    "dm_filter = open('typedm_filter.txt', 'w')\n",
    "i = 0\n",
    "for line in dm:\n",
    "    line_split = line.split('\\t')\n",
    "    w1 = line_split[0][:len(line_split[0])-2]\n",
    "    w2 = line_split[2][:len(line_split[2])-2]\n",
    "    pair1 = [w1,w2]\n",
    "    #not needed: inverse link constraints\n",
    "    pair2 = [w2,w1]\n",
    "    if pair1 in wp or pair2 in wp:\n",
    "        dm_filter.write(w1 + '\\t' + line_split[1] + '\\t'+ w2 + '\\t' + line_split[3])\n",
    "    i += 1\n",
    "dm.close()\n",
    "dm_filter.close()\n",
    "print 'End: '+ str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filter out empty word pairs\n",
    "wp_filter = []\n",
    "for p in wp:\n",
    "    if len(p) == 2:\n",
    "        w1 = p[0]\n",
    "        w2 = p[1]\n",
    "        p = '\"'+ w1+ ':'+ w2 + '\"'\n",
    "        wp_filter.append(p)\n",
    "wp = wp_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3078\n"
     ]
    }
   ],
   "source": [
    "#remove repetitions in the word pairs\n",
    "wp = set(wp)\n",
    "print len(wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs not in DM:1104\n",
      "(1974, 1440) 3078\n"
     ]
    }
   ],
   "source": [
    "#store only entries in DM with word pairs in the dataset\n",
    "dm_filter = open('typedm_filter.txt', 'r')\n",
    "patterns = set()\n",
    "pairs_dm = set()\n",
    "\n",
    "#store patterns and pairs in DM \n",
    "for line in dm_filter:\n",
    "    sp = line.split('\\t')\n",
    "    pattern = sp[1]\n",
    "    patterns.add(pattern)\n",
    "    w1 = sp[0]\n",
    "    w2 = sp[2]\n",
    "    pair = '\"'+ w1+ ':'+ w2 + '\"'\n",
    "    pairs_dm.add(pair)\n",
    "pairs_dm = list(pairs_dm.intersection(wp))\n",
    "wp = list(wp)\n",
    "patterns = list(patterns)\n",
    "dm_filter.close()\n",
    "print 'Pairs not in DM:' + str(len(wp) - len(pairs_dm))\n",
    "#dictionary with word pairs and patterns indeces in the matrix: key: string, value:index\n",
    "pair2index = dict(zip(pairs_dm, xrange(len(wp))))\n",
    "\n",
    "i = 0\n",
    "pat2index = dict(zip(patterns, xrange(len(patterns))))\n",
    "dm_filter = open('typedm_filter.txt', 'r')\n",
    "\n",
    "#matrix with feature vectors (rows: pairs in DM, cols: patterns in DM)\n",
    "feature_vectors = np.zeros(shape=(len(pairs_dm),len(patterns)))\n",
    "for line in dm_filter:\n",
    "    sp = line.split('\\t')\n",
    "    w1 = sp[0]\n",
    "    w2 = sp[2]\n",
    "    pair = '\"'+ w1+ ':'+ w2 + '\"'\n",
    "    if pair in pairs_dm:\n",
    "        row = pair2index[pair]\n",
    "        col = pat2index[sp[1]]\n",
    "        feature_vectors[row,col] = float(sp[3])\n",
    "print feature_vectors.shape, len(wp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving objects in pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#store feature vectors in pickle file and dictionaries for rows and cols\n",
    "\n",
    "pickle.dump(feature_vectors, open('dm_feature_matrix.pkl','wb'))\n",
    "pickle.dump(pair2index, open('dm_pair2index.pkl', 'wb'))\n",
    "pickle.dump(pat2index, open('dm_pat2index.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Classifiers\n",
    "import pickle\n",
    "from classifier import extract_labels, logreg_classify_pairs\n",
    "\n",
    "feature_vectors = pickle.load(open('dm_feature_matrix.pkl', 'rb'))\n",
    "pair2index = pickle.load(open('dm_pair2index.pkl', 'rb'))\n",
    "pat2index = pickle.load(open('dm_pat2index.pkl', 'rb'))\n",
    "\n",
    "semrel_folder_train = 'SemEval-2012-Complete-Data-Package/Training/Phase1Answers'\n",
    "semrel_folder_test = 'SemEval-2012-Complete-Data-Package/Testing/Phase1Answers'\n",
    "\n",
    "#store labels for each sem.rel./classifier\n",
    "\n",
    "y_train= extract_labels(semrel_folder_train, pair2index)[0]\n",
    "y_test = extract_labels(semrel_folder_test, pair2index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic relation: 7a\n",
      "0.613636363636\n",
      "Semantic relation: 10a\n",
      "0.860465116279\n",
      "Semantic relation: 1a\n",
      "0.90243902439\n",
      "Semantic relation: 5i\n",
      "0.681818181818\n",
      "Semantic relation: 2c\n",
      "0.627906976744\n",
      "Semantic relation: 3c\n",
      "0.317073170732\n",
      "Semantic relation: 5d\n",
      "0.295454545455\n",
      "Semantic relation: 3a\n",
      "0.604651162791\n",
      "Semantic relation: 2h\n",
      "0.439024390244\n",
      "Semantic relation: 4c\n",
      "0.627906976744\n"
     ]
    }
   ],
   "source": [
    "logreg_classify_pairs(semrel_folder_train, feature_vectors, pair2index, pat2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic relation: 9i\n",
      "0.846153846154\n",
      "Semantic relation: 7f\n",
      "0.894736842105\n",
      "Semantic relation: 7e\n",
      "0.864864864865\n",
      "Semantic relation: 7d\n",
      "0.931818181818\n",
      "Semantic relation: 7c\n",
      "0.641025641026\n",
      "Semantic relation: 7b\n",
      "0.941176470588\n",
      "Semantic relation: 9h\n",
      "0.790697674419\n",
      "Semantic relation: 9a\n",
      "0.666666666667\n",
      "Semantic relation: 10c\n",
      "0.90243902439\n",
      "Semantic relation: 9c\n",
      "0.62962962963\n",
      "Semantic relation: 9b\n",
      "0.738095238095\n",
      "Semantic relation: 9e\n",
      "0.860465116279\n",
      "Semantic relation: 8h\n",
      "0.720930232558\n",
      "Semantic relation: 10d\n",
      "0.853658536585\n",
      "Semantic relation: 9f\n",
      "0.775\n",
      "Semantic relation: 1d\n",
      "0.116279069767\n",
      "Semantic relation: 5b\n",
      "0.225\n",
      "Semantic relation: 4h\n",
      "0.744186046512\n",
      "Semantic relation: 8e\n",
      "0.85\n",
      "Semantic relation: 7g\n",
      "0.794117647059\n",
      "Semantic relation: 10b\n",
      "0.725\n",
      "Semantic relation: 1c\n",
      "0.97619047619\n",
      "Semantic relation: 3h\n",
      "0.860465116279\n",
      "Semantic relation: 1e\n",
      "0.212121212121\n",
      "Semantic relation: 5h\n",
      "0.533333333333\n",
      "Semantic relation: 5c\n",
      "0.80487804878\n",
      "Semantic relation: 5e\n",
      "0.95\n",
      "Semantic relation: 3b\n",
      "0.790697674419\n",
      "Semantic relation: 5g\n",
      "0.47619047619\n",
      "Semantic relation: 5f\n",
      "0.46511627907\n",
      "Semantic relation: 5a\n",
      "0.97619047619\n",
      "Semantic relation: 3f\n",
      "0.933333333333\n",
      "Semantic relation: 3e\n",
      "0.945945945946\n",
      "Semantic relation: 3d\n",
      "0.547619047619\n",
      "Semantic relation: 6a\n",
      "0.431818181818\n",
      "Semantic relation: 6b\n",
      "0.139534883721\n",
      "Semantic relation: 6c\n",
      "0.613636363636\n",
      "Semantic relation: 6d\n",
      "0.377777777778\n",
      "Semantic relation: 6e\n",
      "0.604651162791\n",
      "Semantic relation: 6f\n",
      "0.279069767442\n",
      "Semantic relation: 6g\n",
      "0.0731707317073\n",
      "Semantic relation: 8b\n",
      "0.763157894737\n",
      "Semantic relation: 8c\n",
      "0.948717948718\n",
      "Semantic relation: 8a\n",
      "0.756097560976\n",
      "Semantic relation: 8f\n",
      "0.780487804878\n",
      "Semantic relation: 8g\n",
      "0.966666666667\n",
      "Semantic relation: 8d\n",
      "0.707317073171\n",
      "Semantic relation: 9d\n",
      "0.785714285714\n",
      "Semantic relation: 10f\n",
      "0.6\n",
      "Semantic relation: 9g\n",
      "0.390243902439\n",
      "Semantic relation: 1b\n",
      "0.975609756098\n",
      "Semantic relation: 10e\n",
      "0.323529411765\n",
      "Semantic relation: 6h\n",
      "0.340909090909\n",
      "Semantic relation: 7h\n",
      "0.9\n",
      "Semantic relation: 3g\n",
      "0.921052631579\n",
      "Semantic relation: 2d\n",
      "0.692307692308\n",
      "Semantic relation: 2e\n",
      "0.45\n",
      "Semantic relation: 2f\n",
      "0.906976744186\n",
      "Semantic relation: 2g\n",
      "0.744186046512\n",
      "Semantic relation: 2a\n",
      "0.772727272727\n",
      "Semantic relation: 2b\n",
      "0.736842105263\n",
      "Semantic relation: 4f\n",
      "0.340909090909\n",
      "Semantic relation: 4g\n",
      "0.333333333333\n",
      "Semantic relation: 4d\n",
      "0.566666666667\n",
      "Semantic relation: 4e\n",
      "0.266666666667\n",
      "Semantic relation: 4b\n",
      "0.371428571429\n",
      "Semantic relation: 2i\n",
      "0.538461538462\n",
      "Semantic relation: 2j\n",
      "0.761904761905\n",
      "Semantic relation: 4a\n",
      "0.395348837209\n"
     ]
    }
   ],
   "source": [
    "logreg_classify_pairs(semrel_folder_test, feature_vectors, pair2index, pat2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store data in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get data in csv format\n",
    "import csv\n",
    "from os import stat, mkdir, path\n",
    "\n",
    "\n",
    "train_dir = 'dm_training_csv'\n",
    "try:\n",
    "    stat(train_dir)\n",
    "except:\n",
    "    mkdir(train_dir)\n",
    "for rel in y_train:\n",
    "    with open(path.join(train_dir, 'dm_featurevectors_'+rel+'_train.csv'), 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        for p in pair2index:\n",
    "            vector = []\n",
    "            for weight in feature_vectors[pair2index[p],]:\n",
    "                vector.append(str(weight))\n",
    "            label = y_train[rel][pair2index[p]]\n",
    "            writer.writerow([p] +  vector + [str(label)])\n",
    "            \n",
    "test_dir = 'dm_testing_csv'\n",
    "try:\n",
    "    stat(test_dir)\n",
    "except:\n",
    "    mkdir(test_dir)   \n",
    "for rel in y_test:\n",
    "    with open(path.join(test_dir, 'dm_featurevectors_'+rel+'_test.csv'), 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter= ',')\n",
    "        for p in pair2index:\n",
    "            vector = []\n",
    "            for weight in feature_vectors[pair2index[p],]:\n",
    "                vector.append(str(weight))\n",
    "            label = y_test[rel][pair2index[p]]\n",
    "            writer.writerow([p] +  vector + [str(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
